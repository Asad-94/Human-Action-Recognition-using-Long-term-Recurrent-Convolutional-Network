# Human-Action-Recognition-using-Recurrent-Convolutional-Network-LRCN-

This project focuses on recognizing actions using a Deep Learning approach called Long-term Recurrent Convolutional Network (LRCN). It combines Convolutional Neural Network (CNN) and Long Short-term Memory (LSTM) models to identify relations between different image sequences.

In this approach, a sequence of frames of YouTube videos are captured as images, and this sequential form of data is passed to the LRCN model for training, eventually predicting human action in the video.

The dataset which is used for this project is UCF101 videos, imported from Kaggle. It contains 101 different action categories of videos, obtained from YouTube. Each category contain 25 groups of videos, while each group has 4â€“7 videos in it. In this way, each action category contains approximately 130 videos, while 101 categories contain a total of around 13,000 videos.

The action categories in UCF101 dataset are divided into Sports, Human-Human interaction, Human-object interaction, Playing Musical Instruments and Body-Motion types. Some of the categories in these types include: Playing Guitar, Skiing, Golf Swing, Baby Crawling, Bench Press, and many others.
